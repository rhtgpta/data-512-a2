{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A2: Bias in Data\n",
    "\n",
    "## The goal of the assignment is to examine bias in Wikipedia's English version, specifically by looking at the articles related to politicians in different countries.\n",
    "The metrics to evaluate bias are as follows:\n",
    "1. Ratio between the number of politician related articles and the countries' population\n",
    "2. Ratio between the number of high-quality politician articles to the overall number of poitician articles\n",
    "\n",
    "The output contains the top 10 extreme countries for both the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# importing packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Retrieval\n",
    "The data for the analysis is coming from 2 sources. \n",
    "\n",
    "Source 1:  \n",
    "Wikipedia Data for all political pages by country  \n",
    "(Link: https://figshare.com/articles/Untitled_Item/5513449)    \n",
    "You need to download the zip file, and extract it. page_data.csv is the file of conern. Or, you can just clone the entire GitHub repository. The file path is written in a way that it will read the relevant file if the Jupyter notebook is running in the root directory.\n",
    "\n",
    "Source 2:  \n",
    "Population Data for \"almost\" all the countries  \n",
    "(Link: https://www.dropbox.com/s/5u7sy1xt7g0oi2c/WPDS_2018_data.csv?dl=0)  \n",
    "You can download the file and read it (not required if cloning from GitHub).\n",
    "\n",
    "Columns in the Wikipedia data:\n",
    "* page: Name of the Wikipedia page that contains the politician related article \n",
    "* country: the country to which the politician belongs\n",
    "* rev_id: the revision id that identifies the last revision to the said page\n",
    "\n",
    "Columns in the population data:\n",
    "* Geography: country name\n",
    "* Population mid-2018 (millions): population size (in millions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reading the population data\n",
    "pop_data = pd.read_csv('./raw_data/WPDS_2018_data.csv')\n",
    "\n",
    "# reading the page data\n",
    "page_data =  pd.read_csv('./raw_data/country/country/data/page_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to fetch the article quality scores, and we ping the Machine Learning service called [ORES](https://www.mediawiki.org/wiki/ORES), provided by Wikimedia API. The service evaluates the quality of an article and classifies all the articles in 6 different classes based on the estimated quality of the written text (FA- Featured Article, GA - Good Article are the high quality ones we are looking for). \n",
    "\n",
    "As per ORES [documentation](https://www.mediawiki.org/wiki/ORES#Article_quality) about article quality, the categories are defined as follows (ordered from best to worst):  \n",
    "  \n",
    "1. FA - Featured article  \n",
    "2. GA - Good article  \n",
    "3. B - B-class article  \n",
    "4. C - C-class article  \n",
    "5. Start - Start-class article  \n",
    "6. Stub - Stub-class article  \n",
    "\n",
    "\n",
    "In terms of hitting the API programmatically, we make a loop such that we only make 100 requests at a time due to rate restrictions. \n",
    "We initialize a Pandas Dataframe to save all the results.  \n",
    "\n",
    "The JSON response for a single revision ID from ORES looks like this:  \n",
    "{\n",
    "    \"enwiki\": {\n",
    "        \"models\": {\n",
    "            \"wp10\": {\n",
    "                \"version\": \"0.5.0\"\n",
    "            }\n",
    "        },\n",
    "        \"scores\": {\n",
    "            \"757539710\": {\n",
    "                \"wp10\": {\n",
    "                    \"score\": {\n",
    "                        \"prediction\": \"Start\",\n",
    "                        \"probability\": {\n",
    "                            \"B\": 0.0950995993086368,\n",
    "                            \"C\": 0.1709859524092081,\n",
    "                            \"FA\": 0.002534267983331672,\n",
    "                            \"GA\": 0.005731369423122624,\n",
    "                            \"Start\": 0.7091352495053856,\n",
    "                            \"Stub\": 0.01651356137031511\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "  \n",
    "We save the rating as a NaN if we do not get a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# header for making ORES pings\n",
    "headers = {'User-Agent' : 'https://github.com/rohitgupta91', 'From' : 'rgupta91@uw.edu'}\n",
    "# endpoint definition\n",
    "endpoint = 'https://ores.wikimedia.org/v3/scores/{project}/?models={model}&revids={revids}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# getting a list of all revision IDs \n",
    "list_revision_id = list(page_data['rev_id'])\n",
    "\n",
    "# getting a list of ids seperated by a distance of 100\n",
    "list_rev_dist = list(np.arange(0, len(list_revision_id), 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# getting the dict of parameters to hit the API\n",
    "# initializing an empty dataframe\n",
    "revid_pd = pd.DataFrame()\n",
    "\n",
    "# variable to store count of rev id where no info found\n",
    "count_no_info = 0\n",
    "\n",
    "# ping with 100 revision ids at a time\n",
    "for i in list_rev_dist:\n",
    "    start_idx = i\n",
    "    end_idx = i + 100\n",
    "    \n",
    "    # getting all the 100 revision ids for the iteration\n",
    "    loop_rev_id = list_revision_id[start_idx:end_idx]\n",
    "    \n",
    "    # getting all ids joined together \n",
    "    rev_ids = '|'.join(str(x) for x in loop_rev_id)\n",
    "        \n",
    "    # defining parameters for the API call\n",
    "    params = {\n",
    "    'project' : 'enwiki',\n",
    "    'model'   : 'wp10',\n",
    "    'revids'  : rev_ids\n",
    "    }\n",
    "\n",
    "    # making an API call and storing the response\n",
    "    api_call = requests.get(endpoint.format(**params))\n",
    "    response = api_call.json()\n",
    "    \n",
    "    # saving the ratings received from the API\n",
    "    for rev_id in loop_rev_id:\n",
    "        try:\n",
    "            rating = response['enwiki']['scores'][str(int(rev_id))]['wp10']['score']['prediction']\n",
    "        # if no ratings fetched for a particular rev-id\n",
    "        # assign NAN value\n",
    "        except:\n",
    "            rating = np.nan\n",
    "            # incrementing the counter of no info\n",
    "            count_no_info = count_no_info + 1\n",
    "        \n",
    "        # appending results to the dataframe\n",
    "        revid_pd = revid_pd.append({'rev_id' : str(int(rev_id)), 'rating' : rating}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>rev_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>235107991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stub</td>\n",
       "      <td>355319463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stub</td>\n",
       "      <td>391862046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stub</td>\n",
       "      <td>391862070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stub</td>\n",
       "      <td>391862409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rating     rev_id\n",
       "0    NaN  235107991\n",
       "1   Stub  355319463\n",
       "2   Stub  391862046\n",
       "3   Stub  391862070\n",
       "4   Stub  391862409"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# snapshot of the resultant data\n",
    "revid_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to retrieve 105 Revision IDs, which is 0.22 % of the total IDs\n"
     ]
    }
   ],
   "source": [
    "# how many revision id not retreived\n",
    "print (\"Unable to retrieve\", count_no_info, \"Revision IDs, which is\", \n",
    "       round(count_no_info/len(list_revision_id),4) * 100,\n",
    "      \"% of the total IDs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We merge the page data with the ORES ratings, and subsequently with the population data. \n",
    "For performing the merge, we need to ensure that the joining variables are in the same type (both strings or integers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merging the two dataframes\n",
    "# converting the page data rev id to a string\n",
    "page_data['rev_id'] = page_data['rev_id'].apply(lambda x: str(x))\n",
    "page_df = pd.merge(revid_pd, page_data, on = \"rev_id\")\n",
    "\n",
    "# merging with the population data\n",
    "final_df = pd.merge(page_df, pop_data, left_on = 'country', right_on = 'Geography')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>rev_id</th>\n",
       "      <th>page</th>\n",
       "      <th>country</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Population mid-2018 (millions)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>235107991</td>\n",
       "      <td>Template:ZambiaProvincialMinisters</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>17.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stub</td>\n",
       "      <td>757566606</td>\n",
       "      <td>Gladys Lundwe</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>17.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stub</td>\n",
       "      <td>764848643</td>\n",
       "      <td>Mwamba Luchembe</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>17.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Start</td>\n",
       "      <td>768166426</td>\n",
       "      <td>Thandiwe Banda</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>17.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C</td>\n",
       "      <td>776082926</td>\n",
       "      <td>Sylvester Chisembele</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>17.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rating     rev_id                                page country Geography  \\\n",
       "0    NaN  235107991  Template:ZambiaProvincialMinisters  Zambia    Zambia   \n",
       "1   Stub  757566606                       Gladys Lundwe  Zambia    Zambia   \n",
       "2   Stub  764848643                     Mwamba Luchembe  Zambia    Zambia   \n",
       "3  Start  768166426                      Thandiwe Banda  Zambia    Zambia   \n",
       "4      C  776082926                Sylvester Chisembele  Zambia    Zambia   \n",
       "\n",
       "  Population mid-2018 (millions)  \n",
       "0                           17.7  \n",
       "1                           17.7  \n",
       "2                           17.7  \n",
       "3                           17.7  \n",
       "4                           17.7  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# snapshot of the resultant data\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Palestinian Territory', 'Hondura', 'Czech Republic', 'Salvadoran',\n",
       "       'Saint Kitts and Nevis', 'Palauan', 'French Guiana', 'Ivorian',\n",
       "       'Saint Vincent and the Grenadines', 'Rhodesian', 'Omani',\n",
       "       'Congo, Dem. Rep. of', 'Niuean', 'East Timorese', 'Faroese',\n",
       "       'Cape Colony', 'South Korean', 'Samoan', 'Montserratian',\n",
       "       'Pitcairn Islands', 'Abkhazia', 'Martinique', 'Carniolan',\n",
       "       'Saint Lucian', 'South African Republic', 'Incan', 'Chechen',\n",
       "       'Jersey', 'Guernsey', 'Guadeloupe', 'South Ossetian', 'Cook Island',\n",
       "       'Tokelauan', 'Swaziland', 'Dagestani', 'Greenlandic', 'Ossetian',\n",
       "       'Somaliland', 'Rojava'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some countries not present in the population dataset\n",
    "no_country = page_df[~page_df['country'].isin(final_df['country'])]\n",
    "no_country.country.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the above result, some of the countries are not present in the population dataset. Hence, we will be losing some rows because we are performing an inner join. Let us see how many countries are not present in the population dataset, and how many rows we lose as a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lost 4.49 % of data due to merging the dataframes\n"
     ]
    }
   ],
   "source": [
    "# how much data loss because of the mismatch in inner join\n",
    "print (\"Lost\", round(1 - len(final_df)/len(page_df),4) * 100, \"% of data due to merging the dataframes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some maintenance tasks, such as renaming, converting population variable from string to an integer, and re-arranging the column structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# manipulating the final dataframe\n",
    "# renaming the population column\n",
    "final_df.rename(columns={'Population mid-2018 (millions)': 'population'}, inplace=True)\n",
    "# renaming the revision id\n",
    "final_df.rename(columns={'rev_id': 'revision_id'}, inplace=True)\n",
    "# renaming article quality\n",
    "final_df.rename(columns={'rating': 'article_quality'}, inplace=True)\n",
    "# renaming article name\n",
    "final_df.rename(columns={'page': 'article_name'}, inplace=True)\n",
    "# converting the population to an integer (from million quantity)\n",
    "final_df['population'] = final_df['population'].apply(lambda x: int(float(x.replace(',', ''))*1000000))\n",
    "\n",
    "# re-arranging and selecting columns\n",
    "final_df = final_df[['country', 'article_name', 'revision_id', 'article_quality', 'population']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>article_name</th>\n",
       "      <th>revision_id</th>\n",
       "      <th>article_quality</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>Template:ZambiaProvincialMinisters</td>\n",
       "      <td>235107991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>Gladys Lundwe</td>\n",
       "      <td>757566606</td>\n",
       "      <td>Stub</td>\n",
       "      <td>17700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>Mwamba Luchembe</td>\n",
       "      <td>764848643</td>\n",
       "      <td>Stub</td>\n",
       "      <td>17700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>Thandiwe Banda</td>\n",
       "      <td>768166426</td>\n",
       "      <td>Start</td>\n",
       "      <td>17700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>Sylvester Chisembele</td>\n",
       "      <td>776082926</td>\n",
       "      <td>C</td>\n",
       "      <td>17700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country                        article_name revision_id article_quality  \\\n",
       "0  Zambia  Template:ZambiaProvincialMinisters   235107991             NaN   \n",
       "1  Zambia                       Gladys Lundwe   757566606            Stub   \n",
       "2  Zambia                     Mwamba Luchembe   764848643            Stub   \n",
       "3  Zambia                      Thandiwe Banda   768166426           Start   \n",
       "4  Zambia                Sylvester Chisembele   776082926               C   \n",
       "\n",
       "   population  \n",
       "0    17700000  \n",
       "1    17700000  \n",
       "2    17700000  \n",
       "3    17700000  \n",
       "4    17700000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# snapshot of the resultant data\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the dataset to the disk...\n"
     ]
    }
   ],
   "source": [
    "# saving the dataset before initiating the analysis\n",
    "print ('Saving the dataset to the disk...')\n",
    "final_df.to_csv('final_dataframe.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "\n",
    "Firstly, we drop all the rows where the rating information was not retrieved from the ORES system. We also create a flag for the high quality articles (FA or GA).  \n",
    "Afterwards, we roll-up the data at a country-level with the total number of articles and high quality articles summed up.  \n",
    "\n",
    "We want to create 2 metrics:\n",
    "1. Ratio between the number of politician articles and the countries' population\n",
    "2. Ratio between the number of high-quality politician articles to the overall number of articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'rating'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/home/rohit/miniconda3/envs/ethics_class/lib/python3.4/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2133\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2134\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2135\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4433)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4279)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13742)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13696)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'rating'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-81e2a518c6e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# creating a flag for high quality articles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mfinal_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'high_count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'GA'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfinal_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'FA'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/rohit/miniconda3/envs/ethics_class/lib/python3.4/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2057\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rohit/miniconda3/envs/ethics_class/lib/python3.4/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2064\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2066\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2068\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rohit/miniconda3/envs/ethics_class/lib/python3.4/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1384\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1386\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1387\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rohit/miniconda3/envs/ethics_class/lib/python3.4/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3542\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3543\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3544\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3545\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rohit/miniconda3/envs/ethics_class/lib/python3.4/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2134\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2136\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4433)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4279)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13742)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13696)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'rating'"
     ]
    }
   ],
   "source": [
    "# starting analysis\n",
    "# removing rows where rating is NaN\n",
    "final_df = final_df.dropna(how='any')  \n",
    "\n",
    "# creating a flag for high quality articles\n",
    "final_df['high_count'] = np.where((final_df['article_quality'] == 'GA') | (final_df['article_quality'] == 'FA'), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rolling the dataset at the country level\n",
    "country_df = pd.pivot_table(\n",
    "    final_df,  \n",
    "    index = ['country','population'],\n",
    "    values = ['high_count'],\n",
    "    aggfunc = [lambda x: len(x), np.sum]\n",
    ").reset_index()\n",
    "\n",
    "# moving index to columns\n",
    "country_df.index.name = country_df.columns.name = None\n",
    "\n",
    "# dropping a level columns\n",
    "country_df.columns = country_df.columns.droplevel()\n",
    "\n",
    "# renaming all column name\n",
    "country_df.columns = ['country','population','num_articles','num_hq_articles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# articles per person in a country (percentage)\n",
    "country_df['art_per_person'] = country_df['num_articles']/country_df['population']*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following tables show the highest and lowest ranked countries in terms of the proportion of politician related articles with population of the country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>population</th>\n",
       "      <th>num_articles</th>\n",
       "      <th>num_hq_articles</th>\n",
       "      <th>art_per_person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Tuvalu</td>\n",
       "      <td>10000</td>\n",
       "      <td>55</td>\n",
       "      <td>5</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Nauru</td>\n",
       "      <td>10000</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>San Marino</td>\n",
       "      <td>30000</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0.273333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Monaco</td>\n",
       "      <td>40000</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Liechtenstein</td>\n",
       "      <td>40000</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0.072500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Tonga</td>\n",
       "      <td>100000</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>0.063000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Marshall Islands</td>\n",
       "      <td>60000</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0.061667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>400000</td>\n",
       "      <td>206</td>\n",
       "      <td>2</td>\n",
       "      <td>0.051500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>80000</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.042500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Federated States of Micronesia</td>\n",
       "      <td>100000</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            country  population  num_articles  \\\n",
       "166                          Tuvalu       10000            55   \n",
       "115                           Nauru       10000            53   \n",
       "135                      San Marino       30000            82   \n",
       "108                          Monaco       40000            40   \n",
       "93                    Liechtenstein       40000            29   \n",
       "161                           Tonga      100000            63   \n",
       "103                Marshall Islands       60000            37   \n",
       "68                          Iceland      400000           206   \n",
       "3                           Andorra       80000            34   \n",
       "52   Federated States of Micronesia      100000            38   \n",
       "\n",
       "     num_hq_articles  art_per_person  \n",
       "166                5        0.550000  \n",
       "115                0        0.530000  \n",
       "135                0        0.273333  \n",
       "108                0        0.100000  \n",
       "93                 0        0.072500  \n",
       "161                1        0.063000  \n",
       "103                0        0.061667  \n",
       "68                 2        0.051500  \n",
       "3                  0        0.042500  \n",
       "52                 0        0.038000  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# highest ranked countries in terms of articles per person\n",
    "country_df.sort_values(by = 'art_per_person', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>population</th>\n",
       "      <th>num_articles</th>\n",
       "      <th>num_hq_articles</th>\n",
       "      <th>art_per_person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>India</td>\n",
       "      <td>1371300000</td>\n",
       "      <td>986</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Indonesia</td>\n",
       "      <td>265200000</td>\n",
       "      <td>214</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>China</td>\n",
       "      <td>1393800000</td>\n",
       "      <td>1135</td>\n",
       "      <td>33</td>\n",
       "      <td>0.000081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Uzbekistan</td>\n",
       "      <td>32900000</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>107500000</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>17700000</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Korea, North</td>\n",
       "      <td>25600000</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>66200000</td>\n",
       "      <td>112</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>166400000</td>\n",
       "      <td>323</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Mozambique</td>\n",
       "      <td>30500000</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          country  population  num_articles  num_hq_articles  art_per_person\n",
       "69          India  1371300000           986               14        0.000072\n",
       "70      Indonesia   265200000           214                8        0.000081\n",
       "34          China  1393800000          1135               33        0.000081\n",
       "173    Uzbekistan    32900000            29                1        0.000088\n",
       "51       Ethiopia   107500000           105                1        0.000098\n",
       "178        Zambia    17700000            25                0        0.000141\n",
       "82   Korea, North    25600000            39                7        0.000152\n",
       "159      Thailand    66200000           112                3        0.000169\n",
       "13     Bangladesh   166400000           323                3        0.000194\n",
       "112    Mozambique    30500000            60                0        0.000197"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lowest ranked countries in terms of articles per person\n",
    "country_df.sort_values(by = 'art_per_person', ascending = True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following tables show the highest and lowest ranked countries in terms of the proportion of high-quality politician related articles with overall number of politician related articles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# high-quality articles per person in a country (percentage)\n",
    "country_df['hq_art_per_person'] = country_df['num_hq_articles']/country_df['num_articles']*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>population</th>\n",
       "      <th>num_articles</th>\n",
       "      <th>num_hq_articles</th>\n",
       "      <th>art_per_person</th>\n",
       "      <th>hq_art_per_person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Korea, North</td>\n",
       "      <td>25600000</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>17.948718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Saudi Arabia</td>\n",
       "      <td>33400000</td>\n",
       "      <td>119</td>\n",
       "      <td>16</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>13.445378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Central African Republic</td>\n",
       "      <td>4700000</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>0.001447</td>\n",
       "      <td>11.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Romania</td>\n",
       "      <td>19500000</td>\n",
       "      <td>348</td>\n",
       "      <td>40</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>11.494253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Mauritania</td>\n",
       "      <td>4500000</td>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>9.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Bhutan</td>\n",
       "      <td>800000</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>0.004125</td>\n",
       "      <td>9.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Tuvalu</td>\n",
       "      <td>10000</td>\n",
       "      <td>55</td>\n",
       "      <td>5</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Dominica</td>\n",
       "      <td>70000</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017143</td>\n",
       "      <td>8.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>United States</td>\n",
       "      <td>328000000</td>\n",
       "      <td>1092</td>\n",
       "      <td>82</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>7.509158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Benin</td>\n",
       "      <td>11500000</td>\n",
       "      <td>94</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>7.446809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      country  population  num_articles  num_hq_articles  \\\n",
       "82               Korea, North    25600000            39                7   \n",
       "137              Saudi Arabia    33400000           119               16   \n",
       "31   Central African Republic     4700000            68                8   \n",
       "132                   Romania    19500000           348               40   \n",
       "104                Mauritania     4500000            52                5   \n",
       "19                     Bhutan      800000            33                3   \n",
       "166                    Tuvalu       10000            55                5   \n",
       "44                   Dominica       70000            12                1   \n",
       "171             United States   328000000          1092               82   \n",
       "18                      Benin    11500000            94                7   \n",
       "\n",
       "     art_per_person  hq_art_per_person  \n",
       "82         0.000152          17.948718  \n",
       "137        0.000356          13.445378  \n",
       "31         0.001447          11.764706  \n",
       "132        0.001785          11.494253  \n",
       "104        0.001156           9.615385  \n",
       "19         0.004125           9.090909  \n",
       "166        0.550000           9.090909  \n",
       "44         0.017143           8.333333  \n",
       "171        0.000333           7.509158  \n",
       "18         0.000817           7.446809  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# highest ranked countries in terms of high-quality articles per person\n",
    "country_df.sort_values(by = 'hq_art_per_person', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>population</th>\n",
       "      <th>num_articles</th>\n",
       "      <th>num_hq_articles</th>\n",
       "      <th>art_per_person</th>\n",
       "      <th>hq_art_per_person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Sao Tome and Principe</td>\n",
       "      <td>200000</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Mozambique</td>\n",
       "      <td>30500000</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Cameroon</td>\n",
       "      <td>25600000</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Guyana</td>\n",
       "      <td>800000</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Turkmenistan</td>\n",
       "      <td>5900000</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Monaco</td>\n",
       "      <td>40000</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Moldova</td>\n",
       "      <td>3500000</td>\n",
       "      <td>426</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012171</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Comoros</td>\n",
       "      <td>800000</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006375</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Marshall Islands</td>\n",
       "      <td>60000</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0.061667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>5000000</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   country  population  num_articles  num_hq_articles  \\\n",
       "136  Sao Tome and Principe      200000            22                0   \n",
       "112             Mozambique    30500000            60                0   \n",
       "28                Cameroon    25600000           105                0   \n",
       "65                  Guyana      800000            20                0   \n",
       "165           Turkmenistan     5900000            33                0   \n",
       "108                 Monaco       40000            40                0   \n",
       "107                Moldova     3500000           426                0   \n",
       "36                 Comoros      800000            51                0   \n",
       "103       Marshall Islands       60000            37                0   \n",
       "38              Costa Rica     5000000           150                0   \n",
       "\n",
       "     art_per_person  hq_art_per_person  \n",
       "136        0.011000                0.0  \n",
       "112        0.000197                0.0  \n",
       "28         0.000410                0.0  \n",
       "65         0.002500                0.0  \n",
       "165        0.000559                0.0  \n",
       "108        0.100000                0.0  \n",
       "107        0.012171                0.0  \n",
       "36         0.006375                0.0  \n",
       "103        0.061667                0.0  \n",
       "38         0.003000                0.0  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lowest ranked countries in terms of high-quality articles per person\n",
    "country_df.sort_values(by = 'hq_art_per_person', ascending = True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lowest-ranked countries for high quality articles are all with 0 proportions, which does not make much sense. Let us see all the countries with no high quality article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 37 countries with no high quality politician article.\n"
     ]
    }
   ],
   "source": [
    "# zero high-quality articles\n",
    "zero_hq = country_df[country_df['num_hq_articles'] == 0]\n",
    "print (\"There are\", len(zero_hq), \"countries with no high quality politician article.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Andorra', 'Angola', 'Antigua and Barbuda', 'Bahamas', 'Barbados',\n",
       "       'Belgium', 'Belize', 'Cameroon', 'Cape Verde', 'Comoros',\n",
       "       'Costa Rica', 'Djibouti', 'Federated States of Micronesia',\n",
       "       'Finland', 'Guyana', 'Kazakhstan', 'Kiribati', 'Lesotho',\n",
       "       'Liechtenstein', 'Macedonia', 'Malta', 'Marshall Islands',\n",
       "       'Moldova', 'Monaco', 'Mozambique', 'Nauru', 'Nepal', 'San Marino',\n",
       "       'Sao Tome and Principe', 'Seychelles', 'Slovakia',\n",
       "       'Solomon Islands', 'Switzerland', 'Tunisia', 'Turkmenistan',\n",
       "       'Uganda', 'Zambia'], dtype=object)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing out all these countries\n",
    "zero_hq['country'].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ethics_class]",
   "language": "python",
   "name": "conda-env-ethics_class-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
